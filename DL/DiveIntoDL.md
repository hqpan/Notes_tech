[toc]



# 版权声明

- 深度学习系列学习笔记来源于 Aston Zhang，Zack C. Lipton，李沐和 Alex J. Smola 所著 *Dive into Deep Learning* [1]；
- 该系列笔记不以盈利为目的，仅用于个人学习、课后复习及科学研究；
- 如有侵权，请与本人联系（hqpan@foxmail.com），经核实后即刻删除；
- 本文采用 [署名-非商业性使用-禁止演绎 4.0 国际 (CC BY-NC-ND 4.0)](https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh) 协议发布；

# 1. 基本概念

## 1.1 定义

- 表征学习：是机器学习中的一类方法，用于自动找出适合表示数据的方式，而深度学习是具有多级表示的表征学习方法，可以逐级表示越来越抽象的概念或模式；

# 1.2 数据操作

- `torch.Tensor`：用于存储和变换数据，类似于多维数组；
  - tensor：n. 张量，可视为一个多维数组；
  - 标量：0维张量；
  - 向量：1维张量；
  - 矩阵：2维张量；

## 1.3 自动求梯度

- 

# 2. 深度学习基础

## 2.1 线性回归

- 损失函数：计算预测值与真实值之间差值的函数；
- 超参数：
  - 人为设定的 参数，而非通过模型训练学到的参数；
  - 调参：一般指反复试错调节超参数；
- 解析解和数值解：
  - 解析解：若模型和损失函数形式较为简单时，其误差最⼩化问题的解可⽤公式表示；
  - 数值解：大多数深度学习模型没有解析解，只能通过优化算法有限次迭代模型参数尽可能降低损失函数的值；
- 特征数：亦称特征向量维度，即神经网络中第一层输入值的个数；
- 输出层不涉及计算，因此计算神经网络层数时不统计输出层；
  - 线性回归可视为一个单层神经网络；
- 全连接层/稠密层：全连接层的每一个结点都与上一层的所有结点相连，将前边提取到的特征综合起来；
- 在一个周期（epoch）中，使用训练数据集将模型训练一次；

# ==待整理内容==

- 链式法则：即反向传播，用于更新网络参数；

# TODO

- 总页数：364 页；
- 每天 10 页，9 月 30 日完成；
- 当前进度：Chapter 3.2 已完成；

# References

[1] Aston Zhang, Zack C. Lipton, Mu Li, Alex J. Smola. Dive into Deep Learning[M]. 人民邮电出版社, 2019. 