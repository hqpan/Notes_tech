# 版权声明

-  Deep Learning 系列笔记来源于Andrew Ng 教授在 Coursera 网站上所授课程《Deep Learning》[^1]；
-  该系列笔记不以盈利为目的，仅用于个人学习、课后复习及交流讨论；
-  如有侵权，请与本人联系（hqpan@foxmail.com），经核实后即刻删除；
-  转载请注明出处；

# 1. 深度学习概论

## 1.1 基本概念

- sigmoid 函数：$\sigma(x)=\frac{1}{1+e^{-x}}$，$x\in(-\infty,+\infty)$；
  - 功能：将$(-\infty,+\infty)$之间的值映射到区间$(0,1)$上；
  - 特点：在$-\infty$和$+\infty$方向上梯度为 0；
  - 使用梯度下降法时，若梯度接近于 0，参数更新将会减缓；
- ReLU函数：
  - ReLU：Rectified Linear Unit，线性修正单元；
  - 修正：指其取值不小于0；
  - 对于大于 0 的输入，其梯度始终为 1；
  - 将 sigmoid 函数替换为 ReLU 函数，将使梯度下降算法运行得更快；
- 隐藏单元：
  - hidden units，即神经网络中的神经元；
  - 根据给定的输入和输出，神经网络自动生成合适的隐藏单元；
- CNN 和 RNN：
  - CNN：常用于处理图像数据；
  - RNN：常用于处理一维时序数据；
- 结构化数据和非结构化数据：
  - 结构化数据：E.g. 数据库中的一张表；
  - 非结构化数据：文本、音频、图像；
- 影响最终性能的因素：
  - 当训练集规模较小时，最终性能取决于开发人员手工设计特征的能力（hand engineer features）及算法处理方面的细节，此时传统机器学习方法的性能可能会超过神经网络；
  - 当训练集规模较小时，最终性能取决于算法模型自身，此时大规模神经网络的性能远胜于传统机器学习方法；

## 1.2 符号含义

- m：训练样本数量，即数据集规模；
  - $m_{train}$：训练集样本数；
  - $m_{test}$：测试集样本数；
- $n_x$：特征向量$x$的维度，有时简写为$n$；
- W、b：
  - W：权重参数；
  - b：阈值；
- $(x,y)$：表示一个样本；
- $(x^{(i)},y^{(i)})$：表示数据集中的第$i$个样本；
- $\widehat{y}$：模型输出的对$y$的预测值；

# 2. 神经网络基础

- 

# Unsolved

- 

# TODO

- 每周完成 2 周课程；
- 每月完成 2 门课程，11 月底完成 Andrew Ng 全部课程；
- 12 月完成 CS 224；
- 当前进度：Course 1，Week 2，2.2 已完成；

# References

[^1]: https://www.coursera.org/specializations/deep-learning?

